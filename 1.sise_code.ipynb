{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "네이버 시가총액 (코스피500개, 코스닥300개)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "save\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import requests\n",
    "import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def stock_data(columns, sosok):\n",
    "    data = list()\n",
    "    data = data + [sosok]\n",
    "    code = list()    \n",
    "    #fn_link = list()\n",
    "    for column in columns:        \n",
    "        data = data + [column.text.strip()]            \n",
    "        a = column.find(\"a\",{\"class\":\"tltle\"})\n",
    "\n",
    "        if a:\n",
    "            code = [a.attrs[\"href\"][20:]]\n",
    "            #code = [\"https://finance.naver.com\" + a.attrs[\"href\"]] \n",
    "            code_str = str(code)[4:10]\n",
    "            #fn_link = \"http://comp.fnguide.com/SVO2/ASP/SVD_Main.asp?pGB=1&gicode=A\"+code_str+\"&cID=&MenuYn=Y&ReportGB=&NewMenuID=11&stkGb=701\"\n",
    "            fn_link = \"https://comp.fnguide.com/SVO/WooriRenewal/Snapshot.asp?pGB=12&gicode=A\"+code_str\n",
    "            #print(fn_link)\n",
    "            data = data + code + [fn_link]\n",
    "\n",
    "    return data[0:-1]\n",
    "\n",
    "\n",
    "\n",
    "today = datetime.date.today().strftime('%y%m%d')\n",
    "filename = today + \"_sise_code.csv\"\n",
    "\n",
    "f = open(filename, \"w\", encoding=\"euc-kr\", newline=\"\")\n",
    "writer = csv.writer(f)\n",
    "\n",
    "title = \"구분,No,종목명,종목코드,fn링크,현재가,전일비,등락률,액면가,시가총액,상장주식수,외국인비율,거래량,PER,ROE\".split(\",\")\n",
    "print(type(title))\n",
    "writer.writerow(title)\n",
    "\n",
    "for sosok in range(2):\n",
    "    if sosok==0:\n",
    "        last_page = 11\n",
    "    else:\n",
    "        last_page = 7    \n",
    "\n",
    "    url = \"https://finance.naver.com/sise/sise_market_sum.nhn?sosok=\" + str(sosok) + \"&page=\"\n",
    "\n",
    "    for page in range(1, last_page):\n",
    "        res =requests.get(url + str(page))\n",
    "        res.raise_for_status()\n",
    "        soup = BeautifulSoup(res.text, \"lxml\")\n",
    "\n",
    "        data_rows = soup.find(\"table\", attrs={\"class\":\"type_2\"}).find(\"tbody\").find_all(\"tr\")\n",
    "        for row in data_rows:\n",
    "            columns = row.find_all(\"td\")\n",
    "            #print(columns)\n",
    "            #print(\"*****\")\n",
    "            if len(columns) <= 1:\n",
    "                continue        \n",
    "            #data = [column.get_text().strip() for column in columns]\n",
    "            #print(data)\n",
    "            #writer.writerow(data)\n",
    "            \n",
    "            data = stock_data(columns, sosok)\n",
    "            #print(type(data))\n",
    "            #print(data)\n",
    "\n",
    "            writer.writerow(data)\n",
    "\n",
    "print('save')\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "관심종목 등락률 조회 / 관심종목에 종목코드 값 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "today = datetime.date.today().strftime('%y%m%d')\n",
    "filename = today + \"_sise_code.csv\"\n",
    "\n",
    "df = pd.read_csv(filename, encoding=\"euc-kr\")\n",
    "df_interest = pd.read_csv(\"interest.csv\", encoding=\"euc-kr\")\n",
    "\n",
    "df['등락률2']=df['등락률'].str.replace('%','').astype(float)\n",
    "df['전일비2']=df['전일비'].str.replace(r'\\s+',' ', regex=True)\n",
    "\n",
    "df_stock = df.loc[:, ['구분','종목명','종목코드','현재가','전일비2','등락률2','외국인비율','PER','ROE']]\n",
    "df_stock_updown_sort = df_stock.sort_values(by=['등락률2','현재가'], ascending=True)\n",
    "# df_stock_siga_sort = df_stock.sort_values(by=['시가총액'])\n",
    "\n",
    "#df_pr_ch = df3.loc[((df3['등락률2'] > 10) | (df3['등락률2'] < -5)) & (df3['외국인비율'] > 5), ['구분','종목명','현재가','전일비2','등락률2','외국인비율','PER','ROE']]\n",
    "#display(df_pr_ch)   \n",
    "\n",
    "interest_list = df_interest['종목명'].tolist()\n",
    "df_sname =df_stock.loc[df_stock['종목명'].isin(interest_list)]                                                                                                                                                                            \n",
    "display(df_sname)\n",
    "\n",
    "f = open(\"interest.csv\", \"w\", encoding=\"euc-kr\", newline=\"\")\n",
    "df_interest_update = df_sname.loc[:,['종목명','종목코드']]\n",
    "df_interest_update.to_csv(f)\n",
    "\n",
    "f.close()\n",
    "\n",
    "print('관심종목 종목코드 입력완료')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "관심종목 실시간 조회"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def naver_data(code):\n",
    "    url = \"https://finance.naver.com/item/main.nhn?code=\" + code    \n",
    "    res =requests.get(url)\n",
    "    res.raise_for_status()\n",
    "    soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "\n",
    "    try :\n",
    "        s_name = soup.find('div',{'class':'h_company'}).find('h2').text.replace(u'\\xa0','')\n",
    "        s_price = soup.find('p',{'class':'no_today'}).find('span',{'class':'blind'}).text.replace(u'\\xa0','')\n",
    "        s_ch = soup.find('p',{'class':'no_exday'}).find_all('em')[0].find('span',{'class':'blind'}).text.replace(u'\\xa0','')\n",
    "        s_ch1 = soup.find('p',{'class':'no_exday'}).find_all('em')[1].find('span',{'class':'ico'}).text.replace(u'\\xa0','')\n",
    "        s_ch2 = soup.find('p',{'class':'no_exday'}).find_all('em')[1].find('span',{'class':'blind'}).text.replace(u'\\xa0','')\n",
    "        #s_pr1 = soup.find('dl',{'class':'blind'}).find_all('dd')[4].text.replace(u'\\xa0','')\n",
    "        #s_pr2 = soup.find('dl',{'class':'blind'}).find_all('dd')[5].text.replace(u'\\xa0','')\n",
    "        s_pr3 = soup.find('dl',{'class':'blind'}).find_all('dd')[6].text.replace(u'\\xa0','')[3:]\n",
    "        s_pr4 = soup.find('dl',{'class':'blind'}).find_all('dd')[8].text.replace(u'\\xa0','')[3:]\n",
    "        s_siga = soup.find('div',{'class':'first'}).find('table').find_all('tr')[0].find('td').find('em').text.strip().replace(u'\\t','').replace(u'\\n','')        \n",
    "        s_fore = soup.find('div',{'class':'gray'}).find('table').find_all('tr')[2].find('td').find('em').text.strip().replace(u'\\t','').replace(u'\\n','')        \n",
    "        s_52h = soup.find('table',{'class':'rwidth'}).find_all('tr')[1].find('td').find_all('em')[0].text\n",
    "        s_52l = soup.find('table',{'class':'rwidth'}).find_all('tr')[1].find('td').find_all('em')[1].text\n",
    "        s_target = soup.find('table',{'class':'rwidth'}).find_all('tr')[0].find('td').find_all('em')[1].text\n",
    "        s_bae = soup.find('table',{'class':'per_table'}).find_all('tr')[3].find('td').find('em').text\n",
    "        \n",
    "        #print(s_name, s_price, s_ch, s_ch1, s_ch2)\n",
    "        #r_data = [s_name, s_price, s_ch, s_ch1, s_ch2, s_pr1, s_pr2, s_pr3, s_pr4]\n",
    "        r_data = [s_name, s_price, s_ch, s_ch1, s_ch2, s_pr3, s_pr4, s_siga, s_fore, s_52h, s_52l, s_target, s_bae]\n",
    "\n",
    "        return r_data\n",
    "    \n",
    "    except:\n",
    "        print('no data'+code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inter = pd.read_csv('interest.csv', encoding=\"euc-kr\")\n",
    "\n",
    "codes = df_inter['종목코드']\n",
    "\n",
    "#i = int()\n",
    "list_realtime = []\n",
    "\n",
    "for code in codes:\n",
    "    #print(code[2:])\n",
    "    #i = i + 1\n",
    "    #print(i)\n",
    "    data1 = naver_data(code[2:])\n",
    "    #print(data1)\n",
    "    try:\n",
    "        list_realtime.append(\n",
    "            {\n",
    "            '종목명'  :data1[0].replace('\\n',''),\n",
    "            '현재가'  :data1[1],\n",
    "            '변동금액':int(data1[2].replace(',','')),\n",
    "            '손익'    :data1[3],\n",
    "            '비율'    :float(data1[4]),\n",
    "            '고가'    :data1[5],\n",
    "            '저가'    :data1[6],\n",
    "            '시총'    :data1[7],\n",
    "            '외국인'    :data1[8],\n",
    "            '52H'    :data1[9],\n",
    "            '52L'    :data1[10],\n",
    "            '목표가'    :data1[11],\n",
    "            '배당률'    :data1[12]                \n",
    "            })\n",
    "    \n",
    "    except:\n",
    "        print('no data1')\n",
    "\n",
    "# display(list_realtime)\n",
    "df_realtime = pd.DataFrame(list_realtime)\n",
    "df_realtime_sort = df_realtime.sort_values(by=['손익','비율','변동금액'], ascending=False)\n",
    "\n",
    "display(df_realtime_sort)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기간별 수익률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def fn_data(code):\n",
    "    url = \"http://comp.fnguide.com/SVO2/ASP/SVD_Main.asp?pGB=1&gicode=A\"+code+\"&cID=&MenuYn=Y&ReportGB=&NewMenuID=11&stkGb=701\"\n",
    "    \n",
    "    res = requests.get(url)\n",
    "    res.raise_for_status()\n",
    "    soup = BeautifulSoup(res.text, 'lxml')    \n",
    "    \n",
    "    try:\n",
    "        s_name = soup.find(\"h1\", {\"id\":\"giName\"}).text.replace(u'\\xa0','')\n",
    "        \n",
    "        #s_code = soup.find(\"h2\").text.replace(u'\\xa0','')\n",
    "        s_code = \"e=\" + code\n",
    "        s_cate = soup.find(\"span\",{\"class\":\"stxt1\"}).text.replace(u'\\xa0',' ')\n",
    "        s_busi = soup.find(\"span\",{\"class\":\"stxt2\"}).text.replace(u'\\xa0',' ')\n",
    "        s_price = soup.find(\"span\",{\"id\":\"svdMainChartTxt11\"}).text.replace(u'\\xa0','')\n",
    "        \n",
    "        s_max_min = soup.find(\"table\",{\"class\":\"us_table_ty1\"}).find(\"tbody\").\\\n",
    "                 find(\"tr\",{\"class\":\"zigbg_in\"}).find(\"td\",{\"class\":\"r\"}).text.replace(u'\\xa0','')\n",
    "        s_mm = s_max_min.split('/')         \n",
    "        \n",
    "        #print(s_name)\n",
    "        \n",
    "        #기간별 수익률\n",
    "        s_1m = soup.find(\"table\",{\"class\":\"us_table_ty1\"}).find(\"tbody\").\\\n",
    "                 find_all(\"tr\")[2].find(\"td\",{\"class\":\"r\"}).find_all(\"span\")[0].text.replace(u'\\xa0','')\n",
    "        s_3m = soup.find(\"table\",{\"class\":\"us_table_ty1\"}).find(\"tbody\").\\\n",
    "                 find_all(\"tr\")[2].find(\"td\",{\"class\":\"r\"}).find_all(\"span\")[1].text.replace(u'\\xa0','')\n",
    "        s_6m = soup.find(\"table\",{\"class\":\"us_table_ty1\"}).find(\"tbody\").\\\n",
    "                 find_all(\"tr\")[2].find(\"td\",{\"class\":\"r\"}).find_all(\"span\")[2].text.replace(u'\\xa0','')\n",
    "        s_1y = soup.find(\"table\",{\"class\":\"us_table_ty1\"}).find(\"tbody\").\\\n",
    "                 find_all(\"tr\")[2].find(\"td\",{\"class\":\"r\"}).find_all(\"span\")[3].text.replace(u'\\xa0','')\n",
    "        s_3y = soup.find(\"input\",{\"id\":\"c3Y\"})[\"value\"]\n",
    "          \n",
    "        #지표\n",
    "        s_eps = soup.find_all(\"table\",{\"class\":\"us_table_ty1\"})[10].find(\"tbody\").\\\n",
    "                 find_all(\"tr\")[18].find_all(\"td\")[2].text.replace(u'\\xa0','')\n",
    "        s_bps = soup.find_all(\"table\",{\"class\":\"us_table_ty1\"})[10].find(\"tbody\").\\\n",
    "                 find_all(\"tr\")[19].find_all(\"td\")[2].text.replace(u'\\xa0','')\n",
    "        s_dps = soup.find_all(\"table\",{\"class\":\"us_table_ty1\"})[10].find(\"tbody\").\\\n",
    "                 find_all(\"tr\")[20].find_all(\"td\")[2].text.replace(u'\\xa0','')\n",
    "        \n",
    "        s_per = soup.find_all(\"table\",{\"class\":\"us_table_ty1\"})[10].find(\"tbody\").\\\n",
    "                 find_all(\"tr\")[21].find_all(\"td\")[2].text.replace(u'\\xa0','')\n",
    "        s_pbr = soup.find_all(\"table\",{\"class\":\"us_table_ty1\"})[10].find(\"tbody\").\\\n",
    "                 find_all(\"tr\")[22].find_all(\"td\")[2].text.replace(u'\\xa0','')\n",
    "        s_pdr = soup.find_all(\"table\",{\"class\":\"us_table_ty1\"})[10].find(\"tbody\").\\\n",
    "                 find_all(\"tr\")[24].find_all(\"td\")[2].text.replace(u'\\xa0','')\n",
    "        \n",
    "        \n",
    "        r_data = [s_name, s_code, s_cate, s_busi, s_price,\\\n",
    "                s_1m, s_3m, s_6m, s_1y, s_3y, s_mm[0], s_mm[1], s_eps, s_bps, s_dps, s_per, s_pbr, s_pdr]\n",
    "\n",
    "        #print(r_data)\n",
    "        return r_data\n",
    "    \n",
    "    except:\n",
    "        s_name = \"\"\n",
    "        s_1m = \"\"\n",
    "        s_3m = \"\"\n",
    "        s_6m = \"\"\n",
    "        s_1y = \"\"\n",
    "        s_3y = \"\"\n",
    "        s_eps = \"\"\n",
    "        s_bps = \"\"\n",
    "        s_dbs = \"\"\n",
    "        s_per = \"\"\n",
    "        s_pbr = \"\"\n",
    "        s_pdr = \"\"\n",
    "        \n",
    "        print(code + \" error\")        \n",
    "\n",
    "\n",
    "    #print(\"---------------------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "today = datetime.date.today().strftime('%y%m%d')\n",
    "filename = today + \"_period_profit.csv\"\n",
    "f = open(filename, \"w\", encoding=\"euc-kr\", newline=\"\")\n",
    "writer = csv.writer(f)\n",
    "\n",
    "title = \"종목명,종목코드,분류KSE,분류FICS,현재가,1개월,3개월,6개월,1년,3년,최고가,최저가,주당순이익,주당순자산,배당금,PER,PBR,배당률\".split(\",\")\n",
    "print(type(title))\n",
    "writer.writerow(title)\n",
    "\n",
    "file_sise = today + \"_sise_code.csv\"\n",
    "df_sise = pd.read_csv(file_sise, encoding=\"euc-kr\")\n",
    "codes = df_sise['종목코드']\n",
    "\n",
    "#print(codes)\n",
    "i = int()\n",
    "\n",
    "for code in codes:\n",
    "    #print(code[2:])\n",
    "    i = i + 1\n",
    "    if i%100==0 : print(i)\n",
    "    data = fn_data(code[2:])   \n",
    "    if data :\n",
    "        #print(code)\n",
    "        #print(data)        \n",
    "        writer.writerow(data)\n",
    "\n",
    "print('save')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분기별 실적 추이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def fn_qt_data(code):\n",
    "    #print(code)\n",
    "    url = \"http://comp.fnguide.com/SVO2/ASP/SVD_Main.asp?pGB=1&gicode=A\"+code+\"&cID=&MenuYn=Y&ReportGB=&NewMenuID=11&stkGb=701\"\n",
    "    #print(url)\n",
    "    res = requests.get(url)\n",
    "    res.raise_for_status()\n",
    "    soup = BeautifulSoup(res.text, 'lxml')\n",
    "    r_data = list()\n",
    "    \n",
    "    try:\n",
    "        s_name = soup.find(\"h1\", {\"id\":\"giName\"}).text.replace(u'\\xa0','')\n",
    "        s_pr = soup.find(\"span\", {\"id\":\"svdMainChartTxt11\"}).text.replace(u'\\xa0','')\n",
    "        #print(s_pr) \n",
    "        #시총\n",
    "        #s_total = soup.find(\"table\",{\"class\":\"us_table_ty1\"}).find(\"tbody\").\\\n",
    "        #         find_all(\"tr\")[3].find(\"td\",{\"class\":\"r\"}).text.replace(u'\\xa0','')\n",
    "        #s_cate = soup.find(\"span\",{\"class\":\"stxt1\"}).text.replace(u'\\xa0',' ')\n",
    "        \n",
    "        #r_data = [s_name, s_total, s_cate]\n",
    "\n",
    "        for i in range(0,8):\n",
    "            #r_data = [s_name]\n",
    "            \n",
    "            #분기 ---------------------------\n",
    "            s_q = soup.find_all(\"table\",{\"class\":\"us_table_ty1\"})[12].find(\"thead\").\\\n",
    "                     find_all(\"tr\")[1].find_all(\"th\")[i].text.replace(u'\\xa0','').strip()[-10:]            \n",
    "            #print(i,s_q)\n",
    "            #매출액\n",
    "            s_mae = soup.find_all(\"table\",{\"class\":\"us_table_ty1\"})[12].find(\"tbody\").\\\n",
    "                     find_all(\"tr\")[0].find_all(\"td\")[i].text.replace(u'\\xa0','')\n",
    "            #영업이익\n",
    "            s_young = soup.find_all(\"table\",{\"class\":\"us_table_ty1\"})[12].find(\"tbody\").\\\n",
    "                     find_all(\"tr\")[1].find_all(\"td\")[i].text.replace(u'\\xa0','')\n",
    "            #영업이익률\n",
    "            #s_yr = soup.find_all(\"table\",{\"class\":\"us_table_ty1\"})[12].find(\"tbody\").\\\n",
    "            #         find_all(\"tr\")[14].find_all(\"td\")[i].text.replace(u'\\xa0','')\n",
    "            s_yr = round(int(s_young.replace(',',''))/int(s_mae.replace(',',''))*100,2)\n",
    "            #print(s_yr)\n",
    "            \n",
    "            #당기순이익\n",
    "            s_dang = soup.find_all(\"table\",{\"class\":\"us_table_ty1\"})[12].find(\"tbody\").\\\n",
    "                     find_all(\"tr\")[3].find_all(\"td\")[i].text.replace(u'\\xa0','')\n",
    "            #전년도ROE\n",
    "            s_roe0 = soup.find_all(\"table\",{\"class\":\"us_table_ty1\"})[11].find(\"tbody\").\\\n",
    "                     find_all(\"tr\")[17].find_all(\"td\")[4].text.replace(u'\\xa0','')\n",
    "            #ROE\n",
    "            s_roe = soup.find_all(\"table\",{\"class\":\"us_table_ty1\"})[12].find(\"tbody\").\\\n",
    "                     find_all(\"tr\")[17].find_all(\"td\")[i].text.replace(u'\\xa0','')\n",
    "            #EPS\n",
    "            s_eps = soup.find_all(\"table\",{\"class\":\"us_table_ty1\"})[12].find(\"tbody\").\\\n",
    "                     find_all(\"tr\")[18].find_all(\"td\")[i].text.replace(u'\\xa0','')            \n",
    "            #DPS\n",
    "            s_dps = soup.find_all(\"table\",{\"class\":\"us_table_ty1\"})[12].find(\"tbody\").\\\n",
    "                     find_all(\"tr\")[20].find_all(\"td\")[i].text.replace(u'\\xa0','')\n",
    "            #PBR\n",
    "            s_pbr = soup.find_all(\"table\",{\"class\":\"us_table_ty1\"})[12].find(\"tbody\").\\\n",
    "                     find_all(\"tr\")[22].find_all(\"td\")[i].text.replace(u'\\xa0','') \n",
    "            \n",
    "            #BPS\n",
    "            s_bps = soup.find_all(\"table\",{\"class\":\"us_table_ty1\"})[12].find(\"tbody\").\\\n",
    "                     find_all(\"tr\")[19].find_all(\"td\")[i].text.replace(u'\\xa0','')\n",
    "            \n",
    "            #BPS가 있을경우 계속\n",
    "            if s_bps:\n",
    "                #price\n",
    "                s_price = format(int(int(s_bps.replace(',','')) * float(s_pbr)), ',')\n",
    "                #print(s_price)\n",
    "                \n",
    "                #10년 복리승수\n",
    "                s_bok = round(1*(1+float(s_roe0)/100)**10, 2)                                    \n",
    "                #s_bok = 1*(1+0.1)**10\n",
    "                #print(float(s_roe0)/100)\n",
    "                #print(s_bok)\n",
    "                \n",
    "                #10년후 자산가치\n",
    "                s_value = int(s_bok * int(s_bps.replace(',',''))) \n",
    "                \n",
    "                #적정가격\n",
    "                s_tp = format(int(s_value / (1*(1+0.15)**10)), ',')\n",
    "                \n",
    "                s_value = format(s_value, ',')\n",
    "                #print(s_value, s_tp)\n",
    "                \n",
    "            else:\n",
    "                s_price = 0\n",
    "                s_bok = 0\n",
    "                s_value = 0\n",
    "                s_tp = 0\n",
    "            \n",
    "            #r_data = r_data + [s_q, s_mae, s_young, s_dang, s_roe, s_eps, s_bps, s_dps, s_pbr]\n",
    "            r_data = [s_name, s_pr, \" \"+s_q, s_mae, s_young, s_dang, s_yr, s_roe0, s_roe, s_eps, s_bps, s_dps, s_pbr, s_price, s_bok, s_value, s_tp]\n",
    "            writer.writerow(r_data)\n",
    "            #display(r_data)\n",
    "            \n",
    "        #return r_data\n",
    "    \n",
    "    except:\n",
    "        s_dang = \"\"\n",
    "        s_roe0 = \"\"\n",
    "        s_roe = \"\"\n",
    "        s_eps = \"\"\n",
    "        s_bps = \"\"\n",
    "        s_dps = \"\"\n",
    "        s_pbr = \"\" \n",
    "        \n",
    "        print(code)\n",
    "\n",
    "\n",
    "    #print(\"---------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "today = datetime.date.today().strftime('%y%m%d')\n",
    "filename = today + \"_quarter_record.csv\"\n",
    "\n",
    "f = open(filename, \"w\", encoding=\"euc-kr\", newline=\"\")\n",
    "writer = csv.writer(f)\n",
    "\n",
    "title = \"종목명,가격,분기,매출액,영업이익,순이익,영업이익률,전년도ROE,ROE,EPS,BPS,DPS,PBR,분기말종가,복리승수(10),자산가치(10),적정가격\".split(\",\")\n",
    "writer.writerow(title)\n",
    "\n",
    "file_sise = today + \"_sise_code.csv\"\n",
    "df_sise = pd.read_csv(file_sise, encoding=\"euc-kr\")\n",
    "codes = df_sise['종목코드']\n",
    "\n",
    "i = int()\n",
    "\n",
    "for code in codes:\n",
    "\n",
    "    fn_qt_data(code[2:])\n",
    "\n",
    "print('save')\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
